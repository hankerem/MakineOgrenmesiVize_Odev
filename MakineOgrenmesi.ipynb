{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "8356de88-942d-4dc4-bb92-f39953795199",
      "cell_type": "markdown",
      "source": "**1. Normalizasyon**\n   Veri setinizi normalleştirmek, farklı ölçeklerde olan özelliklerin modeller tarafından daha etkili bir şekilde işlenmesini sağlar.En yaygın normalleştirme yöntemlerinden biri Min-Max normalleştirmesidir. Bu yöntem, tüm değerleri 0 ile 1 arasında bir ölçeğe dönüştürür.\n   \nDeğişken içinde yer alan sayıları genellikle 0 ve 1 arasına hapseden bir yöntemdir. Min-Max Scalling olarak da bilinir.\r\n\r\nXnorm = (X − Xmin) / (Xmax − Xmin)\r\n\r\nBurada, Xmax ve Xmin sırasıyla değişkene ait değerlerin maksimum ve minimum sayılarını verir.\r\n\r\nX değeri değişkendeki minimum değer olduğunda, pay 0 olacaktır ve dolayısıyla X = 0 olacaktır.\r\nÖte yandan, X’in değeri değişkendeki maksimum değer olduğunda, pay paydaya eşittir olacağından X = 1 sonucu çıkacaktır.\r\nDolayısıyla X’in değeri minimum ve maksimum değer arasındaysa, X’in değeri 0 ile 1 arasında anlamına gelir.",
      "metadata": {}
    },
    {
      "id": "a80cb3c6-6e8a-428f-afc4-908bd8507e1d",
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\ndf = pd.read_csv('veri-seti.txt', header=None, sep='\\t')\ncolumns = ['Number of times pregnant', 'Plasma glucose', 'Diastolic blood pressure', 'Triceps skinfold thickness ', '2-Hour serum insulin', 'Body mass index', 'Diabetes pedigree function.', 'Age', 'Outcome']\ndf.columns = columns\ndf_normalized = (df - df.min()) / (df.max() - df.min())\n\n# İlk beş satırı kontrol edelim\ndf_normalized.head()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Number of times pregnant  Plasma glucose  Diastolic blood pressure  \\\n0                  0.352941        0.743719                  0.590164   \n1                  0.058824        0.427136                  0.540984   \n2                  0.470588        0.919598                  0.524590   \n3                  0.058824        0.447236                  0.540984   \n4                  0.000000        0.688442                  0.327869   \n\n   Triceps skinfold thickness   2-Hour serum insulin  Body mass index  \\\n0                     0.353535              0.000000         0.500745   \n1                     0.292929              0.000000         0.396423   \n2                     0.000000              0.000000         0.347243   \n3                     0.232323              0.111111         0.418778   \n4                     0.353535              0.198582         0.642325   \n\n   Diabetes pedigree function.       Age  Outcome  \n0                     0.234415  0.483333      1.0  \n1                     0.116567  0.166667      0.0  \n2                     0.253629  0.183333      1.0  \n3                     0.038002  0.000000      0.0  \n4                     0.943638  0.200000      1.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Number of times pregnant</th>\n      <th>Plasma glucose</th>\n      <th>Diastolic blood pressure</th>\n      <th>Triceps skinfold thickness</th>\n      <th>2-Hour serum insulin</th>\n      <th>Body mass index</th>\n      <th>Diabetes pedigree function.</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.352941</td>\n      <td>0.743719</td>\n      <td>0.590164</td>\n      <td>0.353535</td>\n      <td>0.000000</td>\n      <td>0.500745</td>\n      <td>0.234415</td>\n      <td>0.483333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.058824</td>\n      <td>0.427136</td>\n      <td>0.540984</td>\n      <td>0.292929</td>\n      <td>0.000000</td>\n      <td>0.396423</td>\n      <td>0.116567</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.470588</td>\n      <td>0.919598</td>\n      <td>0.524590</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.347243</td>\n      <td>0.253629</td>\n      <td>0.183333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.058824</td>\n      <td>0.447236</td>\n      <td>0.540984</td>\n      <td>0.232323</td>\n      <td>0.111111</td>\n      <td>0.418778</td>\n      <td>0.038002</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.688442</td>\n      <td>0.327869</td>\n      <td>0.353535</td>\n      <td>0.198582</td>\n      <td>0.642325</td>\n      <td>0.943638</td>\n      <td>0.200000</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21
    },
    {
      "id": "75b305ee-95b9-4b13-a3dd-0d6fc1de2550",
      "cell_type": "markdown",
      "source": "**2. PCA ve LDA Uygulaması**\nPCA (Principal Component Analysis) ve LDA (Linear Discriminant Analysis) boyut indirgeme tekniğidir. PCA, verinin varyansını maksimize ederek özellikleri dönüştürürken, LDA sınıf ayrımını maksimize eder. Her iki yöntem de genellikle yüksek boyutlu veri setlerini daha az boyutlu bir uzaya indirgemek için kullanılır. Ancak, LDA denetimli bir öğrenme yöntemidir ve sınıf etiketlerini kullanır, PCA ise denetimsiz bir yöntemdir.",
      "metadata": {}
    },
    {
      "id": "d35a9b12-7799-489c-9116-036b347b8326",
      "cell_type": "code",
      "source": "from sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.model_selection import train_test_split\n\nX = df_normalized.drop('Outcome', axis=1)\ny = df_normalized['Outcome']\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nlda = LDA(n_components=1) \nX_lda = lda.fit_transform(X, y)\n\nprint(\"PCA Varyans Oranı:\", pca.explained_variance_ratio_)\nprint(\"LDA Varyans Oranı:\", lda.explained_variance_ratio_ if hasattr(lda, 'explained_variance_ratio_') else \"N/A\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "PCA Varyans Oranı: [0.31192249 0.21186663]\nLDA Varyans Oranı: [1.]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 23
    },
    {
      "id": "bf434844-d675-40c0-a99f-b9b777a8932a",
      "cell_type": "markdown",
      "source": "**3. Çoklu Doğrusal ve Multinominal Lojistjik Regresyon**",
      "metadata": {}
    },
    {
      "id": "7a05c346-4273-4a02-bd8d-431d236b31e3",
      "cell_type": "code",
      "source": "iki veya daha fazla bağımsız değişkeni bir bağımlı değişkenle ilişkilendiren bir denklem bulmak için çoklu doğrusal regresyon modeli kullanılır.\nMultinominal Lojistik Regresyon analizi, bağımlı değişkenin iki veya daha fazla kategorik sınıfa ait olabileceği durumlarda kullanılır.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b8e9dfda-9cc1-450b-a67b-6802a08ed896",
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nlog_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\nlog_reg.fit(X_train, y_train)\nprint(\"Katsayılar:\\n\", log_reg.coef_)\nprint(\"Kesme terimi:\", log_reg.intercept_)\n\n# Test verisi üzerinde performans değerlendirme\ny_pred = log_reg.predict(X_test)\nprint(\"Doğruluk oranı:\", accuracy_score(y_test, y_pred))\nprint(\"Sınıflandırma raporu:\\n\", classification_report(y_test, y_pred))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Katsayılar:\n [[ 0.4505206   2.65118931 -0.24999553  0.03039025 -0.06304149  2.16599472\n   0.45399225  0.90638614]]\nKesme terimi: [-3.25065341]\nDoğruluk oranı: 0.7359307359307359\nSınıflandırma raporu:\n               precision    recall  f1-score   support\n\n         0.0       0.78      0.82      0.80       151\n         1.0       0.63      0.57      0.60        80\n\n    accuracy                           0.74       231\n   macro avg       0.71      0.70      0.70       231\nweighted avg       0.73      0.74      0.73       231\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    },
    {
      "id": "e1df4bb0-6735-4a6f-9bda-d94c6b7e704c",
      "cell_type": "markdown",
      "source": "Bu sonuçlar, modelin diyabet teşhisi konusunda iyi bir doğruluk oranına sahip olduğunu, ancak özellikle pozitif sınıf için (diyabet olanlar) duyarlılık ve kesinliğin daha da iyileştirilebileceğini göstermektedir. Yanlış negatif ve yanlış pozitif oranlarının azaltılması için modelin daha da optimize edilmesi gerekebilir.",
      "metadata": {}
    },
    {
      "id": "5f4b7e96-5187-4a46-af29-6aa9e14d1eaa",
      "cell_type": "markdown",
      "source": "**4. Karar Ağacı Sınıflandırma**",
      "metadata": {}
    },
    {
      "id": "f35fefeb-17c0-497e-aac6-41df17bb410d",
      "cell_type": "code",
      "source": "Karar ağacı sınıflandırma, karmaşık veri setlerini basit karar kurallarına dönüştürerek yorumlanabilirlik sağlar.Anlaşılabilir bir yapıya sahip olduğu için sonuçların nedenleri kolayca anlaşılabilir",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "76dabd6c-9341-4995-b95c-b87b9f6bd07c",
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\ndecision_tree = DecisionTreeClassifier(random_state=42)\ndecision_tree.fit(X_train, y_train)\n\ny_pred_dt = decision_tree.predict(X_test)\naccuracy_dt = accuracy_score(y_test, y_pred_dt)\nconf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\nclass_report_dt = classification_report(y_test, y_pred_dt)\n\nprint(\"Doğruluk (Accuracy):\", accuracy_dt)\nprint(\"Confusion Matrix:\\n\", conf_matrix_dt)\nprint(\"Sınıflandırma Raporu:\\n\", class_report_dt)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Doğruluk (Accuracy): 0.7012987012987013\nConfusion Matrix:\n [[107  44]\n [ 25  55]]\nSınıflandırma Raporu:\n               precision    recall  f1-score   support\n\n         0.0       0.81      0.71      0.76       151\n         1.0       0.56      0.69      0.61        80\n\n    accuracy                           0.70       231\n   macro avg       0.68      0.70      0.69       231\nweighted avg       0.72      0.70      0.71       231\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 26
    },
    {
      "id": "b994c2a9-01da-4957-83f7-9002ef9b4b6c",
      "cell_type": "markdown",
      "source": "Karar Ağacı modeli, diyabet teşhisi konusunda kabul edilebilir bir doğruluk oranı sunmuş, ancak yanlış pozitif ve yanlış negatif oranları dikkate alındığında modelin performansının daha da iyileştirilebileceği görülmektedir. Diyabet olmayanları tespit etme konusunda daha yüksek bir kesinlik sunarken, diyabet olan hastaların tespitinde duyarlılığı artırılabilir.",
      "metadata": {}
    },
    {
      "id": "fe69b539-c0fe-4382-a693-5c3bda0d2ebb",
      "cell_type": "markdown",
      "source": "**5. Naive Bayes Sınıflandırma**",
      "metadata": {}
    },
    {
      "id": "ec20807a-0795-4b82-835c-59d90aeeacd6",
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import GaussianNB\n\nnaive_bayes = GaussianNB()\nnaive_bayes.fit(X_train, y_train)\n\ny_pred_nb = naive_bayes.predict(X_test)\nprint(\"Oran:\", accuracy_score(y_test, y_pred_nb))\nprint(\"Conf. Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\nprint(\"Sınıflandırma:\\n\", classification_report(y_test, y_pred_nb))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Oran: 0.7445887445887446\nConf. Matrix:\n [[119  32]\n [ 27  53]]\nSınıflandırma:\n               precision    recall  f1-score   support\n\n         0.0       0.82      0.79      0.80       151\n         1.0       0.62      0.66      0.64        80\n\n    accuracy                           0.74       231\n   macro avg       0.72      0.73      0.72       231\nweighted avg       0.75      0.74      0.75       231\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 25
    },
    {
      "id": "500fc756-355b-4a7a-aba8-30a772596d5d",
      "cell_type": "markdown",
      "source": "Naive Bayes modeli, test verisi üzerinde %74.46 gibi bir doğruluk oranı ile kabul edilebilir bir performans göstermiştir.Bu sonuçlar, modelin iyileştirilmesi için ek parametre ayarlamaları veya farklı sınıflandırma yöntemlerinin denenmesi gerektiğini göstermektedir.",
      "metadata": {}
    },
    {
      "id": "588d0adf-b606-4067-80f9-54254a693c7d",
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}